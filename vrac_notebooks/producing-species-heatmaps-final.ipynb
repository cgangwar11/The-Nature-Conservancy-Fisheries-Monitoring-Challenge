{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpc2ne4ixr/m91973e5c136ea49268a916ff971b7377.lib and object C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpc2ne4ixr/m91973e5c136ea49268a916ff971b7377.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, '../python_scripts')\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import utils\n",
    "import importlib\n",
    "import threading\n",
    "import meta\n",
    "import heatmap\n",
    "metadata = utils.load(\"./variables/metadata.p\")\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import Iterator\n",
    "import os\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import heatmap\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "from shutil import copyfile\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import time\n",
    "import h_gen,meta,heatmap\n",
    "from meta import *\n",
    "from h_gen import *\n",
    "from utils import *\n",
    "import gc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = [(768, 1216),(1344,2240)]\n",
    "FOLDER_TRAIN = \"./temp_training/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SPLIT = 0.8 # For the train/test split\n",
    "#metadata = meta.create_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img_size in image_size:\n",
    "    dim = str(img_size[0])+'_'+str(img_size[1])+'/'\n",
    "    mk(FOLDER_TRAIN+''+dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angle': -158.4429207149623,\n",
       " 'class': 'ALB',\n",
       " 'code': 2,\n",
       " 'filename': 'img_00003.jpg',\n",
       " 'head_tail': [{'x': 825.5028464692997, 'y': 342.8499725255559},\n",
       "  {'x': 1095.1227277758048, 'y': 449.36646884417524}],\n",
       " 'height': 720,\n",
       " 'ht_first': True,\n",
       " 'path': './train/ALB/img_00003.jpg',\n",
       " 'rectangles': [{'height': 170.61000000000257,\n",
       "   'width': 332.7600000000051,\n",
       "   'x': 805.1100000000123,\n",
       "   'y': 324.30000000000496},\n",
       "  {'height': 258.03000000000395,\n",
       "   'width': 377.88000000000574,\n",
       "   'x': 266.49000000000404,\n",
       "   'y': 135.36000000000206},\n",
       "  {'height': 100.11000000000152,\n",
       "   'width': 360.96000000000555,\n",
       "   'x': 375.0600000000057,\n",
       "   'y': 56.40000000000086},\n",
       "  {'height': 105.75000000000162,\n",
       "   'width': 335.58000000000516,\n",
       "   'x': 690.9000000000106,\n",
       "   'y': 88.83000000000135}],\n",
       " 'width': 1280}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"img_00003.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, let's create the network that will be shared:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is the final network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = [np.zeros((4,4,1,1))]\n",
    "for i in range(4):\n",
    "    n[0][i,i,0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "\n",
    "    x = MaxPooling2D((kernel_size, kernel_size), strides=(1,1),\n",
    "                      border_mode='same', name=conv_name_base + '2b')(input_tensor)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    layer1 = Convolution2D(4, 1, 1, subsample=strides, bias=False, weights=n,\n",
    "                      name=conv_name_base + '2a')\n",
    "    x = layer1(input_tensor)\n",
    "    \n",
    "    layer2 = MaxPooling2D((kernel_size, kernel_size), strides=(1,1), border_mode='same',\n",
    "                      name=conv_name_base + '2b')\n",
    "    x = layer2(x)\n",
    "    \n",
    "\n",
    "    layer3 = Convolution2D(4, 1, 1, subsample=strides, bias=False, weights=n,\n",
    "                             name=conv_name_base + '1')\n",
    "    \n",
    "    shortcut = layer3(input_tensor)\n",
    "    print(layer1.output_shape)\n",
    "    print(layer2.output_shape)\n",
    "    print(layer3.output_shape)\n",
    "    x = merge([x, shortcut], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet501(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None):\n",
    "    '''Instantiate the ResNet50 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        inputs_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "            or `(3, 224, 244)` (with `th` dim ordering).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    img_input = Input(shape=(4,None,None))\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = MaxPooling2D((7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = MaxPooling2D((7, 7),strides=(1,1), name='avg_pool')(x)\n",
    "\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_model(pool_branches = [(2,2), (4,4), (5,5), (8,8),(10,10)]):\n",
    "    nb_input_filters = 1000\n",
    "    N = 36\n",
    "    \n",
    "    img_input = Input(shape=(4,None,None))\n",
    "\n",
    "    W = []\n",
    "    for i in range(N):\n",
    "        if i == 0:\n",
    "            w = img_input\n",
    "            W.append(w)\n",
    "        else:\n",
    "            #if (i+2,i+2) in pool_branches:\n",
    "            w = MaxPooling2D(pool_size=(i+1,i+1), strides=(1,1))(img_input)\n",
    "            W.append(w)\n",
    "\n",
    "    model = Model(input=img_input, output=W)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet501()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = Input(shape=(4,1344,2240))\n",
    "d = resnet(b)\n",
    "x = model1(d)\n",
    "final_model = Model(input=b,output=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's insert the imageNet weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function gives the 4 corners of the rectangle in a mask with a size\n",
    "# different from the image size\n",
    "def get_4_points(rectangle, height,width, target_height, target_width):\n",
    "    ratio_y = height/target_height\n",
    "    ratio_x = width/target_width\n",
    "    new_x = rectangle[\"x\"]/ratio_x\n",
    "    new_y = rectangle[\"y\"]/ratio_y\n",
    "    new_x2 = (rectangle[\"x\"]+rectangle[\"width\"])/ratio_x\n",
    "    new_y2 = (rectangle[\"y\"]+rectangle[\"height\"])/ratio_y\n",
    "    result = np.zeros((4,2))\n",
    "    result[:2,0] = new_x\n",
    "    result[2:,0] = new_x2\n",
    "    result[0,1] = new_y\n",
    "    result[2,1] = new_y\n",
    "    result[1,1] = new_y2\n",
    "    result[3,1] = new_y2\n",
    "    result[:,0].clip(min=0, max=target_width-1, out=result[:,0])\n",
    "    result[:,1].clip(min=0, max=target_height-1, out=result[:,1])\n",
    "    result = result.astype(int)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# This is to remove the useless first dimention because our batch\n",
    "# size is one.\n",
    "def remove_dims(list_matrices):\n",
    "    return [x[0] for x in list_matrices]\n",
    "\n",
    "\n",
    "# This function takes a matrix and multiply all the sub-matrix\n",
    "# element-wise along the axis 0.\n",
    "def elementwise_multiplication(matrix):\n",
    "    \n",
    "    result = np.ones(matrix.shape[1:])\n",
    "    for i in range(matrix.shape[0]):\n",
    "        np.multiply(result, matrix[i], out = result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def fuse_squares(matrix):\n",
    "    \n",
    "    result = np.ones(matrix.shape[1:])*0.5\n",
    "    \n",
    "    no_fish = np.where(np.sum(matrix,axis=0)==0)\n",
    "    fish = np.where(elementwise_multiplication(matrix)==1)\n",
    "    \n",
    "    result[no_fish]=1\n",
    "    result[fish]=0\n",
    "\n",
    "    return result\n",
    "\n",
    "def fuse_fishes(matrix):\n",
    "    result = np.ones(matrix.shape[1:])*0.5\n",
    "    \n",
    "    no_fish = np.where(elementwise_multiplication(matrix)==1)\n",
    "    fish = np.where(elementwise_multiplication(matrix)==0)\n",
    "    \n",
    "    result[no_fish]=1\n",
    "    result[fish]=0\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_zones(res):\n",
    "    return [ fuse_squares(matrix) for matrix in res]\n",
    "\n",
    "def get_zones_with_rects(list_masks):\n",
    "    \n",
    "    # Reshaping phase:\n",
    "    list_reshaped = []\n",
    "    for j in range(len(list_masks[0])):\n",
    "        matrix = np.zeros((len(list_masks),) + list_masks[0][j].shape)\n",
    "        for i in range(len(list_masks)):\n",
    "            matrix[i] = list_masks[i][j]\n",
    "        list_reshaped.append(matrix)\n",
    "        \n",
    "    # Now we do the intersection and stuff\n",
    "    return [fuse_fishes(matrix) for matrix in list_reshaped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAD8CAYAAADe49kaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMggSgDIIEoAyCBKAMggSgDL+C0YNEI2ZVUEVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2327fc235c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.ones((1,5,6))\n",
    "a[0,0] = 0\n",
    "plt.imshow(array_to_img(a))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-5d3e48ef3c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mmatrice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mout_branches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mout_branches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_branches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mlist_masks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_zones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_branches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras-1.2.1-py3.5.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1273\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras-1.2.1-py3.5.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    944\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\keras-1.2.1-py3.5.egg\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder1 = \"folder_store_masks/npy/\"\n",
    "folder2 = \"folder_store_masks/png/\"\n",
    "utils.mk(folder1)\n",
    "utils.mk(folder2)\n",
    "for key, v in tq(list(metadata.items())):\n",
    "    if v[\"class\"] != \"NoF\":\n",
    "        if \"rectangles\" in v:\n",
    "            \n",
    "            utils.mk(folder1 + v[\"filename\"])\n",
    "            utils.mk(folder2 + v[\"filename\"])\n",
    "            \n",
    "            list_masks = []\n",
    "            \n",
    "            for rec in v[\"rectangles\"]:\n",
    "                points = get_4_points(rec, v[\"height\"], v[\"width\"], 1344, 2240)\n",
    "                matrice = np.zeros((1,4,1344,2240))\n",
    "                \n",
    "                for k in range(4):\n",
    "                    matrice[0,k,points[k,1],points[k,0]] = 1\n",
    "\n",
    "                out_branches = final_model.predict(matrice)\n",
    "                out_branches = remove_dims(out_branches)\n",
    "                list_masks.append(get_zones(out_branches))\n",
    "                \n",
    "            if len(list_masks)>1:\n",
    "                list_masks = get_zones_with_rects(list_masks)\n",
    "            elif len(list_masks) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                list_masks = list_masks[0]\n",
    "                \n",
    "            # We create the one hot encoding and save the result.\n",
    "            for mask in list_masks:\n",
    "                \n",
    "                one_hot = np.zeros((8,) + mask.shape)\n",
    "                \n",
    "                # We fill the one hot encoding vector. No value means that we don't know the result.\n",
    "                one_hot[0][np.where(mask==1)]=1\n",
    "                one_hot[v[\"code\"]][np.where(mask==0)]=1\n",
    "                \n",
    "                # We save also the mask for debug purposes.\n",
    "                array_to_img(np.expand_dims(mask,0)).save(folder2 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]) + \".png\")\n",
    "                \n",
    "                one_hot = one_hot.astype(bool)\n",
    "                utils.save_array(one_hot, folder1 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]))\n",
    "        \n",
    "                    \n",
    "    # No fish case\n",
    "    else:\n",
    "        \n",
    "        # We create the one hot encoding heatmap and save the result.\n",
    "        for i in range(1,37):\n",
    "            utils.mk(folder1 + v[\"filename\"])\n",
    "            utils.mk(folder2 + v[\"filename\"])\n",
    "            \n",
    "            one_hot = np.zeros((8,i,i+28))\n",
    "            one_hot[0,:,:]=1\n",
    "            \n",
    "            array_to_img(np.expand_dims(one_hot[0],0)).save(folder2 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]) + \".png\")\n",
    "            \n",
    "            one_hot = one_hot.astype(bool)\n",
    "            utils.save_array(one_hot, folder1 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "presque\n",
    "ça marche\n",
    "cool\n",
    "bah en fait il y a une petite bourde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,0,1]).astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need the last weights of the resnet50:\n",
    "resnet = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap.insert_weights(resnet.layers[-1], model.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = \"models/resnet_mask_training.h5\"\n",
    "mk('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can now save the model.\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth step, training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del resnet\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = \"models/resnet_mask_training.h5\"\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=adam, sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, training_set, metadata,image_size)\n",
    "test_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size)\n",
    "history = model.fit_generator(train_gen, samples_per_epoch=2, nb_epoch=150, callbacks=[remote], \n",
    "                              verbose=0,validation_data=test_gen, nb_val_samples=2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[2].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=sgd, sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, training_set, metadata,image_size)\n",
    "test_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size)\n",
    "history = model.fit_generator(train_gen, samples_per_epoch=2, nb_epoch=25, callbacks=[remote], \n",
    "                              verbose=0,validation_data=test_gen, nb_val_samples=2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_trained = \"models/fish_detection_trained_1.1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(file_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(file_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth step, display results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STATISCAL ANALYSIS OF MEAN_MAX RESULTS </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Final = []\n",
    "c = tq(total=100*16)\n",
    "N = 100\n",
    "n = 0\n",
    "for X, Y, W , paths,is_rects in DiskArrayIterator(16, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size, with_name=True, shuffle=False,debug2=True):\n",
    "    Z = model.predict(X)   \n",
    "    n +=1\n",
    "    if n < N:\n",
    "        for i in range(16):\n",
    "            c.update()\n",
    "            maxs = []\n",
    "            for j in range(5):\n",
    "                maxs.append(np.max(Z[j][i]))\n",
    "            mean_max = np.array(maxs).mean()\n",
    "            try:\n",
    "                Final.append([mean_max,is_rects[i]])\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        break\n",
    "import pickle        \n",
    "pickle.dump( Final, open( \"Final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final = pickle.load( open( \"Final.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF TEST : 1560\n",
      "mean w_f : 0.648588\n",
      "mean wo_f : 0.246224\n",
      "min w_f : 0.0959474\n",
      "min wo_f : 0.059991\n",
      "std w_f : 0.271008\n",
      "std wo_f : 0.129603\n",
      "THRESHOLD : 0.377581\n"
     ]
    }
   ],
   "source": [
    "w_f = []\n",
    "wo_f = []\n",
    "for i in range(len(Final)):\n",
    "    if Final[i][1]:\n",
    "        w_f.append(Final[i][0])\n",
    "    else:\n",
    "        wo_f.append(Final[i][0])\n",
    "w_f = np.array(w_f) \n",
    "wo_f = np.array(wo_f) \n",
    "print('LENGTH OF TEST : '+str(len(Final)))\n",
    "print('mean w_f : '+str(np.array(w_f).mean()))\n",
    "print('mean wo_f : '+str(np.array(wo_f).mean()))\n",
    "print('min w_f : '+str(np.array(w_f).min()))\n",
    "print('min wo_f : '+str(np.array(wo_f).min()))\n",
    "print('std w_f : '+str(np.array(w_f).std()))\n",
    "print('std wo_f : '+str(np.array(wo_f).std()))\n",
    "print('THRESHOLD : '+str(np.array(w_f).mean() - np.array(w_f).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'heatmaps_to_rect' from '../python_scripts\\\\heatmaps_to_rect.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(htr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(paths[i])\n",
    "    plt.imshow(load_img(paths[i]))\n",
    "    plt.show()\n",
    "    maxs = []\n",
    "    for j in range(5):\n",
    "        plt.figure(figsize=(24,24))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(np.reshape(Y[j][i],mask_size[1]))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(np.reshape(Z[j][i],mask_size[1]))\n",
    "        plt.show()\n",
    "        print(\"max: \", np.max(Z[j][i]))\n",
    "        print(\"min: \", np.min(Z[j][i]))\n",
    "        maxs.append(np.max(Z[j][i]))\n",
    "    mean_max = np.array(maxs).mean()\n",
    "    masks = np.array([np.reshape(Z[j][i],mask_size[1]) for j in range(5)])\n",
    "    print(masks.shape)\n",
    "    #rectangles = htr.find_rectangles([masks],mean_max, threshold=100, ranges=(5,20), clip=0.20, debug=True,\n",
    "    #                    border_conf=[(11,3),(71,10)], batch_size=1, max_fish=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "186a2c751a50412ebbeaff64bee74646": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
