{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import json\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tq\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tq\n",
    "from random import shuffle\n",
    "import os\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.optimizers import *\n",
    "from shutil import copyfile\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Analysis of images with rectangle </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir('./')\n",
    "lab_f_names = []\n",
    "jsonFile = collections.defaultdict(list)\n",
    "for f in files:\n",
    "    if '.json' in f:\n",
    "        lab_f_names.append(f)\n",
    "for fjson in lab_f_names:\n",
    "    with open(fjson,'r+') as f:\n",
    "        jsonFile[fjson] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './train/train/'\n",
    "test_path = './test/test/'\n",
    "cropped_images_test = './cropped_test/'\n",
    "cropped_images_train = './cropped_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1719, 200, 117, 67, 465, 299, 176, 734]\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "obj = [len(os.listdir(train_path+direc+'/')) for direc in os.listdir('./train/train/') if direc!='.DS_Store']\n",
    "print(obj)\n",
    "min_dir_images = obj[3]\n",
    "print(min_dir_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n"
     ]
    }
   ],
   "source": [
    "#Create output dir\n",
    "obj = [direc for direc in os.listdir('./train/train/') if direc!='.DS_Store']\n",
    "print(obj)\n",
    "for direc in obj:\n",
    "    try:\n",
    "        os.stat(cropped_images_test+direc)\n",
    "    except:\n",
    "        os.mkdir(cropped_images_test+direc)\n",
    "for direc in obj:\n",
    "    try:\n",
    "        os.stat(cropped_images_train+direc)\n",
    "    except:\n",
    "        os.mkdir(cropped_images_train+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lag_labels.json', 'shark_labels.json', 'alb_labels.json', 'yft_labels.json', 'bet_labels.json', 'dol_labels.json', 'other_labels.json']\n"
     ]
    }
   ],
   "source": [
    "keys = [key for key in jsonFile.keys()]\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAG\n",
      "SHARK\n",
      "ALB\n",
      "YFT\n",
      "BET\n",
      "DOL\n",
      "OTHER\n"
     ]
    }
   ],
   "source": [
    "imgs_cropped = collections.defaultdict(list)\n",
    "max_h = 0\n",
    "max_w = 0\n",
    "alpha = 0.7\n",
    "other = ['OTHER','NoF']\n",
    "for key in jsonFile.keys():\n",
    "    count = 0\n",
    "    dir_fishes = key.split('_')[0].upper()\n",
    "    print(dir_fishes)\n",
    "    L = len(jsonFile[key])\n",
    "    for ele in tq(jsonFile[key]):\n",
    "        if count <= int(alpha*L): \n",
    "            if '/' in ele['filename']:\n",
    "                img_name = ele['filename'].split('/')[-1]\n",
    "            else:\n",
    "                img_name = ele['filename']\n",
    "            annotations = ele['annotations']\n",
    "            dir_fishes = key.split('_')[0].upper()\n",
    "            if dir_fishes not in other:\n",
    "                input_dir = train_path+dir_fishes           \n",
    "                img_path = input_dir+'/'+img_name\n",
    "                name =  '_'.join(img_path.split('/')[-2:])           \n",
    "                imgs_cropped[name] = collections.defaultdict(int)\n",
    "                for i,annotation in enumerate(annotations):\n",
    "                    h = annotation['height']\n",
    "                    w = annotation['width']\n",
    "                    x = annotation['x']\n",
    "                    y = annotation['y']\n",
    "                    img = Image.open(img_path)\n",
    "                    img2 = img.crop((x, y, x+w, y+h))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                    output_name = cropped_images_train+dir_fishes+'/'+str(i)+'_'+img_name\n",
    "                    img2.save(output_name)\n",
    "                count+=1\n",
    "            else:\n",
    "                input_dir = train_path+dir_fishes           \n",
    "                img_path = input_dir+'/'+img_name\n",
    "                name =  '_'.join(img_path.split('/')[-2:])           \n",
    "                imgs_cropped[name] = collections.defaultdict(int)\n",
    "                for i,annotation in enumerate(annotations):\n",
    "                    h = annotation['height']\n",
    "                    w = annotation['width']\n",
    "                    x = annotation['x']\n",
    "                    y = annotation['y']\n",
    "                    img = Image.open(img_path)\n",
    "                    img2 = img.crop((x, y, x+w, y+h))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                    output_name = cropped_images_train+dir_fishes+'/'+str(i)+'_'+img_name\n",
    "                    img2.save(output_name)\n",
    "                #output_name = cropped_images_train+dir_fishes+'/-1'+'_'+img_name\n",
    "                #img.save(output_name)\n",
    "                count+=1               \n",
    "                \n",
    "        else:\n",
    "            if '/' in ele['filename']:\n",
    "                img_name = ele['filename'].split('/')[-1]\n",
    "            else:\n",
    "                img_name = ele['filename']\n",
    "            annotations = ele['annotations']\n",
    "            dir_fishes = key.split('_')[0].upper()\n",
    "            if dir_fishes not in other:\n",
    "                input_dir = train_path+dir_fishes           \n",
    "                img_path = input_dir+'/'+img_name\n",
    "                name =  '_'.join(img_path.split('/')[-2:])           \n",
    "                imgs_cropped[name] = collections.defaultdict(int)\n",
    "                for i,annotation in enumerate(annotations):\n",
    "                    h = annotation['height']\n",
    "                    w = annotation['width']\n",
    "                    x = annotation['x']\n",
    "                    y = annotation['y']\n",
    "                    img = Image.open(img_path)\n",
    "                    img2 = img.crop((x, y, x+w, y+h))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                    output_name = cropped_images_test+dir_fishes+'/'+str(i)+'_'+img_name\n",
    "                    img2.save(output_name)\n",
    "                count+=1\n",
    "            else:\n",
    "                input_dir = train_path+dir_fishes           \n",
    "                img_path = input_dir+'/'+img_name\n",
    "                name =  '_'.join(img_path.split('/')[-2:])           \n",
    "                imgs_cropped[name] = collections.defaultdict(int)\n",
    "                for i,annotation in enumerate(annotations):\n",
    "                    h = annotation['height']\n",
    "                    w = annotation['width']\n",
    "                    x = annotation['x']\n",
    "                    y = annotation['y']\n",
    "                    img = Image.open(img_path)\n",
    "                    img2 = img.crop((x, y, x+w, y+h))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                    output_name = cropped_images_test+dir_fishes+'/'+str(i)+'_'+img_name\n",
    "                    img2.save(output_name)\n",
    "                #output_name = cropped_images_test+dir_fishes+'/-1'+'_'+img_name\n",
    "                #img.save(output_name)\n",
    "                count+=1                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_other = './binary_dataset/train/not_fish/' \n",
    "No_fish_imgs = os.listdir(path_other)\n",
    "random_No_fish = []\n",
    "N = 2000\n",
    "while len(random_No_fish) < N:\n",
    "    img = random.choice(No_fish_imgs)\n",
    "    if img not in random_No_fish:\n",
    "        random_No_fish.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_pictures(train_folder, class_folder, generator,total_images, \n",
    "                        batch_size = 32, target_size = (256,256)):\n",
    "    #count = 0  \n",
    "    \n",
    "    gen_folder = train_folder + \"_gen/\"\n",
    "        \n",
    "    if not os.path.exists(gen_folder):\n",
    "        os.makedirs(gen_folder)\n",
    "        \n",
    "    if not os.path.exists(gen_folder + class_folder):\n",
    "        os.makedirs(gen_folder + class_folder)\n",
    "        \n",
    "    count = len(os.listdir(gen_folder + class_folder))        \n",
    "    \n",
    "    progbar = tq(total = total_images, leave=False)\n",
    "    progbar.update(count)\n",
    "    \n",
    "    \n",
    "    for X in generator.flow_from_directory(train_folder, target_size=target_size,\n",
    "                                             classes=[class_folder], \n",
    "                                             save_to_dir=train_folder + \"_gen/\" + class_folder, \n",
    "                                             batch_size=batch_size, color_mode=\"rgb\"):\n",
    "        count +=batch_size\n",
    "        progbar.update(batch_size)\n",
    "        if count >= total_images:\n",
    "            break\n",
    "    progbar.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_generator = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=2,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01,\n",
    "    shear_range=0.001,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=None,\n",
    "    noise = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def equilibrate_dataset(folder, nb_images_per_class, generator,batch_size,target_size):\n",
    "    for string in os.listdir(folder):\n",
    "        print(string)\n",
    "        create_new_pictures(folder, string, generator,nb_images_per_class, batch_size,target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB\n",
      "Found 1741 images belonging to 1 classes.\n",
      "BET\n",
      "Found 206 images belonging to 1 classes.\n",
      "DOL\n",
      "Found 86 images belonging to 1 classes.\n",
      "LAG\n",
      "Found 73 images belonging to 1 classes.\n",
      "NoF\n",
      "Found 6138 images belonging to 1 classes.\n",
      "OTHER\n",
      "Found 274 images belonging to 1 classes.\n",
      "SHARK\n",
      "Found 136 images belonging to 1 classes.\n",
      "YFT\n",
      "Found 557 images belonging to 1 classes.\n",
      "_gen\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8253be8898e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mequilibrate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_images_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmy_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-913398be8443>\u001b[0m in \u001b[0;36mequilibrate_dataset\u001b[0;34m(folder, nb_images_per_class, generator, batch_size, target_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcreate_new_pictures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_images_per_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-66e212b5e8c0>\u001b[0m in \u001b[0;36mcreate_new_pictures\u001b[0;34m(train_folder, class_folder, generator, total_images, batch_size, target_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                              \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_folder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                              \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_gen/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                              batch_size=batch_size, color_mode=\"rgb\"):\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mindex_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_flow_index\u001b[0;34m(self, N, batch_size, shuffle, seed)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mcurrent_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mcurrent_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "equilibrate_dataset(cropped_images_train,2000,my_generator,16,(None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB\n",
      "Found 790 images belonging to 1 classes.\n",
      "BET\n",
      "Found 101 images belonging to 1 classes.\n",
      "DOL\n",
      "Found 38 images belonging to 1 classes.\n",
      "LAG\n",
      "Found 28 images belonging to 1 classes.\n",
      "NoF\n",
      "Found 630 images belonging to 1 classes.\n",
      "OTHER\n",
      "Found 115 images belonging to 1 classes.\n",
      "SHARK\n",
      "Found 60 images belonging to 1 classes.\n",
      "YFT\n",
      "Found 266 images belonging to 1 classes.\n",
      "_gen\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2fdd27f8b20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mequilibrate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_images_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmy_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-913398be8443>\u001b[0m in \u001b[0;36mequilibrate_dataset\u001b[0;34m(folder, nb_images_per_class, generator, batch_size, target_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcreate_new_pictures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_images_per_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-66e212b5e8c0>\u001b[0m in \u001b[0;36mcreate_new_pictures\u001b[0;34m(train_folder, class_folder, generator, total_images, batch_size, target_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                              \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_folder\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                              \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_gen/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                              batch_size=batch_size, color_mode=\"rgb\"):\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mindex_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_flow_index\u001b[0;34m(self, N, batch_size, shuffle, seed)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mcurrent_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mcurrent_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "equilibrate_dataset(cropped_images_test,500,my_generator,16,(None,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "03e583006dde4fdea40c349792f7eecf": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "06e185d5cd144d669437e42d9fc25896": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "110df0b35734413bb03aa08863147980": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "258d21dc885d49cf8189de2ac1e023ea": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "2faa4bb9c85444b98470d07ffc2c9063": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "3815b47014434e9e8a7195e1ac9dd860": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "38ea5c4483234cc9b4d9c620492381d0": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "4e8f60928c684ef887ebda57f8581b4d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "62fdaf8ce5474f72956ee9ecd4731955": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "96e6d90f932e4a12828b0b1559aa0a20": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a37ac2b5b6944e0aa6c65568f2a60ba9": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b74b0f98ead8409a88851f74efb6e0de": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "bbfc11ca142d432dada6393464042b60": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "bdba85809228491da956b208fdd24832": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c8cca8006ef143d3b15660dd6372d61e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d89dad5041694412935f7836974d53e4": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e5c6bbdcf3d842b788c828061a38b93b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e7e9d08db2844974ad0afd6f70f87540": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
