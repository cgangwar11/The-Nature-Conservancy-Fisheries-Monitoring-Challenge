{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../python_scripts')\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import utils\n",
    "import importlib\n",
    "import threading\n",
    "import meta\n",
    "import heatmap\n",
    "#metadata = utils.load(\"./variables/metadata.p\")\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import Iterator\n",
    "import os\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import heatmap\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "from shutil import copyfile\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import time\n",
    "import h_gen,meta,heatmap\n",
    "from meta import *\n",
    "from h_gen import *\n",
    "from utils import *\n",
    "import gc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = [(768, 1216),(1344,2240)]\n",
    "FOLDER_TRAIN = \"./temp_training/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../JSONS/alb_labels.json', '../JSONS/bet_labels.json', '../JSONS/dol_labels.json', '../JSONS/lag_labels.json', '../JSONS/other_labels.json', '../JSONS/shark_labels.json', '../JSONS/yft_labels.json']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SPLIT = 0.8 # For the train/test split\n",
    "metadata = meta.create_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img_size in image_size:\n",
    "    dim = str(img_size[0])+'_'+str(img_size[1])+'/'\n",
    "    mk(FOLDER_TRAIN+''+dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'ALB',\n",
       " 'cluster': 0,\n",
       " 'code': 2,\n",
       " 'filename': 'img_00003.jpg',\n",
       " 'height': 720,\n",
       " 'path': '../train/train/ALB/img_00003.jpg',\n",
       " 'rectangles': [{'height': 258.03000000000395,\n",
       "   'width': 377.88000000000574,\n",
       "   'x': 266.49000000000404,\n",
       "   'y': 135.36000000000206},\n",
       "  {'height': 100.11000000000152,\n",
       "   'width': 360.96000000000555,\n",
       "   'x': 375.0600000000057,\n",
       "   'y': 56.40000000000086},\n",
       "  {'height': 105.75000000000162,\n",
       "   'width': 335.58000000000516,\n",
       "   'x': 690.9000000000106,\n",
       "   'y': 88.83000000000135},\n",
       "  {'height': 170.61000000000257,\n",
       "   'width': 332.7600000000051,\n",
       "   'x': 805.1100000000123,\n",
       "   'y': 324.30000000000496}],\n",
       " 'width': 1280}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"img_00003.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, let's create the network that will be shared:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is the final network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = [np.zeros((5,5,1,1))]\n",
    "for i in range(5):\n",
    "    n[0][i,i,0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "\n",
    "    x = MaxPooling2D((kernel_size, kernel_size), strides=(1,1),\n",
    "                      border_mode='same', name=conv_name_base + '2b')(input_tensor)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    layer1 = Convolution2D(5, 1, 1, subsample=strides, bias=False, weights=n,\n",
    "                      name=conv_name_base + '2a')\n",
    "    x = layer1(input_tensor)\n",
    "    \n",
    "    layer2 = MaxPooling2D((kernel_size, kernel_size), strides=(1,1), border_mode='same',\n",
    "                      name=conv_name_base + '2b')\n",
    "    x = layer2(x)\n",
    "    \n",
    "\n",
    "    layer3 = Convolution2D(5, 1, 1, subsample=strides, bias=False, weights=n,\n",
    "                             name=conv_name_base + '1')\n",
    "    \n",
    "    shortcut = layer3(input_tensor)\n",
    "    print(layer1.output_shape)\n",
    "    print(layer2.output_shape)\n",
    "    print(layer3.output_shape)\n",
    "    x = merge([x, shortcut], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet501(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None):\n",
    "    '''Instantiate the ResNet50 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        inputs_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "            or `(3, 224, 244)` (with `th` dim ordering).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    img_input = Input(shape=(5,None,None))\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = MaxPooling2D((7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = MaxPooling2D((7, 7),strides=(1,1), name='avg_pool')(x)\n",
    "\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_model(pool_branches = [(2,2), (4,4), (5,5), (8,8),(10,10)]):\n",
    "    nb_input_filters = 1000\n",
    "    N = 36\n",
    "    \n",
    "    img_input = Input(shape=(5,None,None))\n",
    "\n",
    "    W = []\n",
    "    for i in range(N):\n",
    "        if i == 0:\n",
    "            w = img_input\n",
    "            W.append(w)\n",
    "        else:\n",
    "            #if (i+2,i+2) in pool_branches:\n",
    "            w = MaxPooling2D(pool_size=(i+1,i+1), strides=(1,1))(img_input)\n",
    "            W.append(w)\n",
    "\n",
    "    model = Model(input=img_input, output=W)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet501()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = Input(shape=(5,1344,2240))\n",
    "d = resnet(b)\n",
    "x = model1(d)\n",
    "final_model = Model(input=b,output=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's insert the imageNet weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function gives the 4 corners of the rectangle in a mask with a size\n",
    "# different from the image size\n",
    "def get_4_points(rectangle, height,width, target_height, target_width):\n",
    "    ratio_y = height/target_height\n",
    "    ratio_x = width/target_width\n",
    "    new_x = rectangle[\"x\"]/ratio_x\n",
    "    new_y = rectangle[\"y\"]/ratio_y\n",
    "    new_x2 = (rectangle[\"x\"]+rectangle[\"width\"])/ratio_x\n",
    "    new_y2 = (rectangle[\"y\"]+rectangle[\"height\"])/ratio_y\n",
    "    result = np.zeros((5,2))\n",
    "    result[:2,0] = new_x\n",
    "    result[2:,0] = new_x2\n",
    "    result[0,1] = new_y\n",
    "    result[2,1] = new_y\n",
    "    result[1,1] = new_y2\n",
    "    result[3,1] = new_y2\n",
    "    result[:,0].clip(min=0, max=target_width-1, out=result[:,0])\n",
    "    result[:,1].clip(min=0, max=target_height-1, out=result[:,1])\n",
    "    result[4] = (result[0] + result[3])/2\n",
    "    result = result.astype(int)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# This is to remove the useless first dimention because our batch\n",
    "# size is one.\n",
    "def remove_dims(list_matrices):\n",
    "    return [x[0] for x in list_matrices]\n",
    "\n",
    "\n",
    "# This function takes a matrix and multiply all the sub-matrix\n",
    "# element-wise along the axis 0.\n",
    "def elementwise_multiplication(matrix):\n",
    "    \n",
    "    result = np.ones(matrix.shape[1:])\n",
    "    for i in range(matrix.shape[0]):\n",
    "        np.multiply(result, matrix[i], out = result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def fuse_squares(matrix):\n",
    "    \n",
    "    result = np.ones(matrix.shape[1:])*0.5\n",
    "    \n",
    "    no_fish = np.where(np.sum(matrix,axis=0)==0)\n",
    "    fish = np.where(elementwise_multiplication(matrix)==1)\n",
    "    \n",
    "    result[no_fish]=1\n",
    "    result[fish]=0\n",
    "\n",
    "    return result\n",
    "\n",
    "def fuse_fishes(matrix):\n",
    "    result = np.ones(matrix.shape[1:])*0.5\n",
    "    \n",
    "    no_fish = np.where(elementwise_multiplication(matrix)==1)\n",
    "    fish = np.where(elementwise_multiplication(matrix)==0)\n",
    "    \n",
    "    result[no_fish]=1\n",
    "    result[fish]=0\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_zones(res):\n",
    "    return [ fuse_squares(matrix) for matrix in res]\n",
    "\n",
    "def get_zones_with_rects(list_masks):\n",
    "    \n",
    "    # Reshaping phase:\n",
    "    list_reshaped = []\n",
    "    for j in range(len(list_masks[0])):\n",
    "        matrix = np.zeros((len(list_masks),) + list_masks[0][j].shape)\n",
    "        for i in range(len(list_masks)):\n",
    "            matrix[i] = list_masks[i][j]\n",
    "        list_reshaped.append(matrix)\n",
    "        \n",
    "    # Now we do the intersection and stuff\n",
    "    return [fuse_fishes(matrix) for matrix in list_reshaped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAFdCAYAAAAg10vhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6eGiZPZTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27e00e56da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.ones((1,5,6))\n",
    "a[0,0] = 0\n",
    "plt.imshow(array_to_img(a))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder1 = \"folder_store_masks/npy/\"\n",
    "folder2 = \"folder_store_masks/png/\"\n",
    "utils.mk(folder1)\n",
    "utils.mk(folder2)\n",
    "for key, v in tq(list(metadata.items())):\n",
    "    if v[\"class\"] != \"NoF\":\n",
    "        if \"rectangles\" in v:\n",
    "            \n",
    "            utils.mk(folder1 + v[\"filename\"])\n",
    "            utils.mk(folder2 + v[\"filename\"])\n",
    "            \n",
    "            list_masks = []\n",
    "            \n",
    "            for rec in v[\"rectangles\"]:\n",
    "                points = get_4_points(rec, v[\"height\"], v[\"width\"], 1344, 2240)\n",
    "                matrice = np.zeros((1, points.shape[0] ,1344,2240))\n",
    "                \n",
    "                for k in range(points.shape[0]):\n",
    "                    matrice[0,k,points[k,1],points[k,0]] = 1\n",
    "\n",
    "                out_branches = final_model.predict(matrice)\n",
    "                out_branches = remove_dims(out_branches)\n",
    "                list_masks.append(get_zones(out_branches))\n",
    "                \n",
    "            if len(list_masks)>1:\n",
    "                list_masks = get_zones_with_rects(list_masks)\n",
    "            elif len(list_masks) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                list_masks = list_masks[0]\n",
    "                \n",
    "            # We create the one hot encoding and save the result.\n",
    "            for mask in list_masks:\n",
    "                \n",
    "                one_hot = np.zeros((8,) + mask.shape)\n",
    "                \n",
    "                # We fill the one hot encoding vector. No value means that we don't know the result.\n",
    "                one_hot[0][np.where(mask==1)]=1\n",
    "                one_hot[v[\"code\"]][np.where(mask==0)]=1\n",
    "                \n",
    "                # We save also the mask for debug purposes.\n",
    "                array_to_img(np.expand_dims(mask,0)).save(folder2 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]) + \".png\")\n",
    "                \n",
    "                one_hot = one_hot.astype(bool)\n",
    "                utils.save_array(one_hot, folder1 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]))\n",
    "        \n",
    "                    \n",
    "    # No fish case\n",
    "    else:\n",
    "        \n",
    "        # We create the one hot encoding heatmap and save the result.\n",
    "        for i in range(1,37):\n",
    "            utils.mk(folder1 + v[\"filename\"])\n",
    "            utils.mk(folder2 + v[\"filename\"])\n",
    "            \n",
    "            one_hot = np.zeros((8,i,i+28))\n",
    "            one_hot[0,:,:]=1\n",
    "            \n",
    "            array_to_img(np.expand_dims(one_hot[0],0)).save(folder2 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]) + \".png\")\n",
    "            \n",
    "            one_hot = one_hot.astype(bool)\n",
    "            utils.save_array(one_hot, folder1 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([0,0,1]).astype(bool).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need the last weights of the resnet50:\n",
    "resnet = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap.insert_weights(resnet.layers[-1], model.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = \"models/resnet_mask_training.h5\"\n",
    "mk('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can now save the model.\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth step, training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del resnet\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = \"models/resnet_mask_training.h5\"\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=adam, sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, training_set, metadata,image_size)\n",
    "test_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size)\n",
    "history = model.fit_generator(train_gen, samples_per_epoch=2, nb_epoch=150, callbacks=[remote], \n",
    "                              verbose=0,validation_data=test_gen, nb_val_samples=2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[2].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=sgd, sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, training_set, metadata,image_size)\n",
    "test_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size)\n",
    "history = model.fit_generator(train_gen, samples_per_epoch=2, nb_epoch=25, callbacks=[remote], \n",
    "                              verbose=0,validation_data=test_gen, nb_val_samples=2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_trained = \"models/fish_detection_trained_1.1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(file_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(file_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth step, display results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STATISCAL ANALYSIS OF MEAN_MAX RESULTS </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final = []\n",
    "c = tq(total=100*16)\n",
    "N = 100\n",
    "n = 0\n",
    "for X, Y, W , paths,is_rects in DiskArrayIterator(16, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size, with_name=True, shuffle=False,debug2=True):\n",
    "    Z = model.predict(X)   \n",
    "    n +=1\n",
    "    if n < N:\n",
    "        for i in range(16):\n",
    "            c.update()\n",
    "            maxs = []\n",
    "            for j in range(5):\n",
    "                maxs.append(np.max(Z[j][i]))\n",
    "            mean_max = np.array(maxs).mean()\n",
    "            try:\n",
    "                Final.append([mean_max,is_rects[i]])\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        break\n",
    "import pickle        \n",
    "pickle.dump( Final, open( \"Final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final = pickle.load( open( \"Final.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_f = []\n",
    "wo_f = []\n",
    "for i in range(len(Final)):\n",
    "    if Final[i][1]:\n",
    "        w_f.append(Final[i][0])\n",
    "    else:\n",
    "        wo_f.append(Final[i][0])\n",
    "w_f = np.array(w_f) \n",
    "wo_f = np.array(wo_f) \n",
    "print('LENGTH OF TEST : '+str(len(Final)))\n",
    "print('mean w_f : '+str(np.array(w_f).mean()))\n",
    "print('mean wo_f : '+str(np.array(wo_f).mean()))\n",
    "print('min w_f : '+str(np.array(w_f).min()))\n",
    "print('min wo_f : '+str(np.array(wo_f).min()))\n",
    "print('std w_f : '+str(np.array(w_f).std()))\n",
    "print('std wo_f : '+str(np.array(wo_f).std()))\n",
    "print('THRESHOLD : '+str(np.array(w_f).mean() - np.array(w_f).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(htr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(paths[i])\n",
    "    plt.imshow(load_img(paths[i]))\n",
    "    plt.show()\n",
    "    maxs = []\n",
    "    for j in range(5):\n",
    "        plt.figure(figsize=(24,24))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(np.reshape(Y[j][i],mask_size[1]))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(np.reshape(Z[j][i],mask_size[1]))\n",
    "        plt.show()\n",
    "        print(\"max: \", np.max(Z[j][i]))\n",
    "        print(\"min: \", np.min(Z[j][i]))\n",
    "        maxs.append(np.max(Z[j][i]))\n",
    "    mean_max = np.array(maxs).mean()\n",
    "    masks = np.array([np.reshape(Z[j][i],mask_size[1]) for j in range(5)])\n",
    "    print(masks.shape)\n",
    "    #rectangles = htr.find_rectangles([masks],mean_max, threshold=100, ranges=(5,20), clip=0.20, debug=True,\n",
    "    #                    border_conf=[(11,3),(71,10)], batch_size=1, max_fish=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "44ed7ba6a51943a2b6eb79af77764015": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "74a85cdd12724c24a11cfeda38cd2eee": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
