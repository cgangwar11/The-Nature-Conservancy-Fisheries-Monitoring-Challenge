{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import json\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import pickle\n",
    "with open(\"test_rectangles.p\",\"rb\") as f:\n",
    "        my_list = pickle.load(f)\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.optimizers import *\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import csv\n",
    "from sklearn.metrics import log_loss\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open Image Net Images\n",
    "\n",
    "def untar_imagenet():\n",
    "    img_net_path = 'n02622955.tar'\n",
    "    tar = tarfile.open(img_net_path)\n",
    "    tar.extractall(path=\"./n02622955/\")\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def erase_JPEG():\n",
    "    for f in os.listdir('./'):\n",
    "        if '.JPEG' in f:\n",
    "            os.system('rm '+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try to create dataset from \n",
    "files = os.listdir('./')\n",
    "lab_f_names = []\n",
    "jsonFile = collections.defaultdict(list)\n",
    "for f in files:\n",
    "    if '.json' in f:\n",
    "        lab_f_names.append(f)\n",
    "for fjson in lab_f_names:\n",
    "    with open(fjson,'r+') as f:\n",
    "        jsonFile[fjson] = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fish_train', 'not_fish_train']\n",
      "['fist_test', 'not_fish_test']\n"
     ]
    }
   ],
   "source": [
    "binary_folder_train = './binary_dataset/train/'\n",
    "binary_folder_test = './binary_dataset/test/'\n",
    "train_path = './train/train/'\n",
    "subFolder_train = [i for i in os.listdir(binary_folder_train) if i!= '.ipynb_checkpoints' and 'train' in i]\n",
    "subFolder_test = [i for i in os.listdir(binary_folder_test) if i!= '.ipynb_checkpoints' and 'test' in i]\n",
    "print(subFolder_train)\n",
    "print(subFolder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1719, 200, 117, 67, 465, 299, 176, 734]\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "obj = [len(os.listdir(train_path+direc+'/')) for direc in os.listdir('./train/train/') if direc!='.DS_Store']\n",
    "print(obj)\n",
    "min_dir_images = obj[3]\n",
    "print(min_dir_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def is_separate(rect_a, rect_b):\n",
    "    try:\n",
    "        xa,ya,xa2,ya2 = rect_a[0][0],rect_a[0][1],rect_a[1][0],rect_a[1][1]\n",
    "        xb,yb,xb2,yb2 = rect_b[0][0],rect_b[0][1],rect_b[1][0],rect_b[1][1]   \n",
    "        separate = xa2 < xb or ya2 < yb or xa > xb2 or ya > yb2\n",
    "    except:\n",
    "        print(rect_a, rect_b)\n",
    "    if separate == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def transform_rect(rect,size):\n",
    "    w,h = size[0],size[1]\n",
    "    if int(rect[0]+rect[2]) <= w and int(rect[1]+rect[3]) <= h: \n",
    "        return [(rect[0],rect[1]),(rect[0]+rect[2],rect[1]+rect[3])]\n",
    "    \n",
    "def rect_generator(d_x,d_y,size):\n",
    "    rects = []\n",
    "    N_img = int(size[0]/d_x)\n",
    "    for i in range(N_img):\n",
    "        for j in range(N_img):\n",
    "            rects.append(transform_rect([i*d_x,j*d_y,d_x,d_y],size))\n",
    "    return rects\n",
    "            \n",
    "    \n",
    "def cut_and_get_no_fish_img(d_x,d_y,poisson_pos,img):\n",
    "    right_rects = []\n",
    "    img_size = img.size\n",
    "    rects = rect_generator(d_x,d_y,img_size) \n",
    "    if poisson_pos == []:\n",
    "        return rects\n",
    "    else:\n",
    "        for recta in rects:\n",
    "            if recta != None :\n",
    "                good = 0\n",
    "                for rectb in poisson_pos:\n",
    "                    if transform_rect(rectb,img_size) != None:\n",
    "                        good+=is_separate(recta,transform_rect(rectb,img_size))\n",
    "                        if good == 1:\n",
    "                            break\n",
    "                if good == 0:\n",
    "                    right_rects.append(recta)\n",
    "        return right_rects\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOL/\n",
      "\n",
      "ALB/\n",
      "\n",
      "LAG/\n",
      "\n",
      "BET/\n",
      "\n",
      "YFT/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "N = 5\n",
    "alpha = 0.8\n",
    "for key in jsonFile:\n",
    "    directory = key[:3].upper()+'/'\n",
    "    print(directory)\n",
    "    M = len(jsonFile[key])\n",
    "    count = 0\n",
    "    for element in tq(jsonFile[key]):\n",
    "        if count < int(alpha*M): \n",
    "            filename = element['filename']\n",
    "            if '/' in filename:\n",
    "                filename = filename.split('/')[-1]\n",
    "            annotations = element['annotations']\n",
    "            img_path = train_path+directory+filename\n",
    "            img = Image.open(img_path)\n",
    "            size = img.size\n",
    "            d_x,d_y = int(size[0]/N),int(size[1]/N)\n",
    "            poisson_pos = []\n",
    "            for annotation in annotations:\n",
    "                x = annotation['x']\n",
    "                y = annotation['y']\n",
    "                w = annotation['width']\n",
    "                h = annotation['height'] \n",
    "                poisson_pos.append([x,y,w,h])\n",
    "            sub_rects = cut_and_get_no_fish_img(d_x,d_y,poisson_pos,img)\n",
    "            # NO FISHES TRAIN \n",
    "            for k,rect in enumerate(sub_rects):\n",
    "                x = rect[0][0]\n",
    "                y = rect[0][1]\n",
    "                x2 = rect[1][0]\n",
    "                y2 = rect[1][1]\n",
    "                img2 = img.crop((x, y, x2, y2))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                output_name = binary_folder_train+subFolder_train[1]+'/'+str(k)+'_'+filename\n",
    "                img2.save(output_name)\n",
    "            # FISHES TRAIN \n",
    "            if poisson_pos != None and poisson_pos != []:\n",
    "                try:\n",
    "                    for k,rect in enumerate(poisson_pos):\n",
    "                        rect_t = transform_rect(rect,size)\n",
    "                        x = rect_t[0][0]\n",
    "                        y = rect_t[0][1]\n",
    "                        x2 = rect_t[1][0]\n",
    "                        y2 = rect_t[1][1]\n",
    "                        img2 = img.crop((x, y, x2, y2))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                        output_name = binary_folder_train+subFolder_train[0]+'/'+str(k)+'_'+filename\n",
    "                        img2.save(output_name)\n",
    "                except:\n",
    "                    continue\n",
    "            count+=1\n",
    "        else:\n",
    "            filename = element['filename']\n",
    "            if '/' in filename:\n",
    "                filename = filename.split('/')[-1]\n",
    "            annotations = element['annotations']\n",
    "            img_path = train_path+directory+filename\n",
    "            img = Image.open(img_path)\n",
    "            size = img.size\n",
    "            d_x,d_y = int(size[0]/N),int(size[1]/N)\n",
    "            poisson_pos = []\n",
    "            for annotation in annotations:\n",
    "                x = annotation['x']\n",
    "                y = annotation['y']\n",
    "                w = annotation['width']\n",
    "                h = annotation['height'] \n",
    "                poisson_pos.append([x,y,w,h])\n",
    "            sub_rects = cut_and_get_no_fish_img(d_x,d_y,poisson_pos,img)\n",
    "            # NO FISHES TRAIN \n",
    "            for k,rect in enumerate(sub_rects):\n",
    "                x = rect[0][0]\n",
    "                y = rect[0][1]\n",
    "                x2 = rect[1][0]\n",
    "                y2 = rect[1][1]\n",
    "                img2 = img.crop((x, y, x2, y2))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                output_name = binary_folder_test+subFolder_test[1]+'/'+str(k)+'_'+filename\n",
    "                img2.save(output_name)\n",
    "            # FISHES TRAIN \n",
    "            if poisson_pos != None and poisson_pos != []:\n",
    "                try:\n",
    "                    for k,rect in enumerate(poisson_pos):\n",
    "                        rect_t = transform_rect(rect,size)\n",
    "                        x = rect_t[0][0]\n",
    "                        y = rect_t[0][1]\n",
    "                        x2 = rect_t[1][0]\n",
    "                        y2 = rect_t[1][1]\n",
    "                        img2 = img.crop((x, y, x2, y2))#.resize((size), PIL.Image.ANTIALIAS)\n",
    "                        output_name = binary_folder_test+subFolder_test[0]+'/'+str(k)+'_'+filename\n",
    "                        img2.save(output_name)\n",
    "                except:\n",
    "                    continue\n",
    "            count+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def untar_imagenet(name):\n",
    "    img_net_path = name+'.tar'\n",
    "    tar = tarfile.open(img_net_path)\n",
    "    tar.extractall(path=\"./\"+name+\"/\")\n",
    "    tar.close()\n",
    "untar_imagenet('n02512053')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.optimizers import *\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "import csv\n",
    "from sklearn.metrics import log_loss\n",
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3280 images belonging to 1 classes.\n",
      "Found 11800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "binary_folder_train = './binary_dataset/train/'\n",
    "binary_folder_train_fish = binary_folder_train+'fish'\n",
    "binary_folder_train_not_fish = binary_folder_train+'not_fish'\n",
    "binary_folder_val = './binary_dataset/test/'\n",
    "\n",
    "data_gen_args = dict(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.1,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=None,\n",
    "    dim_ordering=K.image_dim_ordering())\n",
    "\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "validation_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(binary_folder_train, batch_size=16,save_to_dir=binary_folder_train_fish,target_size=(480,360),classes=['Fish'])\n",
    "validation_generator = validation_datagen.flow_from_directory(binary_folder_val, batch_size=16,save_to_dir=binary_folder_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\preprocessing\\image.py:346: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn'tbeen fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in train_generator:\n",
    "    if len(os.listdir(binary_folder_train_fish)) <= len(os.listdir(binary_folder_train_not_fish)):\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98943 images belonging to 2 classes.\n",
      "Found 98943 images belonging to 2 classes.\n",
      "Found 11800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "binary_folder_train = './binary_dataset/train/'\n",
    "binary_folder_train_fish = binary_folder_train+'fish'\n",
    "binary_folder_train_not_fish = binary_folder_train+'not_fish'\n",
    "binary_folder_test = './binary_dataset/test/'\n",
    "\n",
    "data_gen_args = dict(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.1,\n",
    "    )\n",
    "\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "validation_datagen = ImageDataGenerator(**data_gen_args)\n",
    "test_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(binary_folder_train, batch_size=16)\n",
    "validation_generator = validation_datagen.flow_from_directory(binary_folder_train, batch_size=16)\n",
    "test_generator = validation_datagen.flow_from_directory(binary_folder_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Activation(activation=\"relu\", input_shape=(3,None,None)))\n",
    "\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1))) \n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1))) \n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1))) \n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1))) \n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "opt = SGD(lr=1e-3, decay=1e-6, momentum=0.001, nesterov=True)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model target: expected activation_12 to have shape (None, 1) but got array with shape (16, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-35f1ba76815c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         nb_val_samples=256, callbacks=[remote])\n\u001b[0m",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1450\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1452\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m                                                            \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m                                                            check_batch_dim=True)\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    965\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m    968\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m    969\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32mD:\\Software\\Anaconda3\\lib\\site-packages\\keras\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                         \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                                         \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                                         str(array.shape))\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model target: expected activation_12 to have shape (None, 1) but got array with shape (16, 2)"
     ]
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_generator,\n",
    "        samples_per_epoch=1024,\n",
    "        nb_epoch=10,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=0,\n",
    "        nb_val_samples=256, callbacks=[remote])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    max = 0\n",
    "    j = 0 \n",
    "    for i in range(len(result)):\n",
    "        if max < result[i]:\n",
    "            max = result[i]\n",
    "            j = i\n",
    "    index_max = j\n",
    "    output = []\n",
    "    for i in range(len(result)):\n",
    "        if i == index_max:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(0) \n",
    "    return output\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "result = []\n",
    "t0 = time.time()\n",
    "time_limit = 10\n",
    "for X_batch, Y_batch in test_generator:\n",
    "    results = model.predict(X_batch)\n",
    "    j = 0\n",
    "    for i in range(len(results)):\n",
    "        im = np.rollaxis(np.array(X_batch[i]), 0, 3) *-1\n",
    "        np.roll(im, 1, axis=-1)\n",
    "        plt.imshow(im,cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "        print(\"True value:\" + str(Y_batch[i]))\n",
    "        print(\"Predicted value\" + str(get_result(results[i])))\n",
    "        if str(get_result(results[i])) == str([int(n) for n in list(Y_batch[i])]):\n",
    "            j+=1\n",
    "        if i == len(results) -1:\n",
    "            result.append(j/len(results))\n",
    "    t1 = time.time()\n",
    "    if (t1-t0) > time_limit:\n",
    "        break\n",
    "sum=0\n",
    "min = 1 \n",
    "max = 0\n",
    "print(result)\n",
    "for n in result:\n",
    "    if n < min:\n",
    "        min = n\n",
    "    if n > max:\n",
    "        max = n\n",
    "    sum+=n\n",
    "print(len(result),sum/len(result),max,min)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "236450781ac3405ca23f42a8e5c281bd": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "5370b9d759804fd79938e45ac60cb6ec": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "79a92851f9294d2694220c328fb42690": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "837f07d177e14f7b83ec98eba168056f": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "951ae2e3bc504bf696faa2d27b1934e4": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "abdf467b4e1d4304b5f3232244367ac3": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "ac47b7fd983843b38d72048492266fae": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "dee4ba60795c44438abf1054d897d3d3": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f360cce0b71948f1a13a5f32cf8f5d12": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
