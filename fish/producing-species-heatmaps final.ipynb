{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpvchindqx/m91973e5c136ea49268a916ff971b7377.lib and object C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpvchindqx/m91973e5c136ea49268a916ff971b7377.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 970 (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\theano\\sandbox\\cuda\\__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, '../python_scripts')\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import utils\n",
    "import importlib\n",
    "import threading\n",
    "import meta\n",
    "import heatmap\n",
    "metadata = utils.load(\"./variables/metadata.p\")\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import Iterator\n",
    "import os\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import heatmap\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "from shutil import copyfile\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import time\n",
    "import h_gen,meta,heatmap\n",
    "from meta import *\n",
    "from h_gen import *\n",
    "from utils import *\n",
    "import gc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = [(768, 1216),(1344,2240)]\n",
    "FOLDER_TRAIN = \"./temp_training/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SPLIT = 0.8 # For the train/test split\n",
    "#metadata = meta.create_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img_size in image_size:\n",
    "    dim = str(img_size[0])+'_'+str(img_size[1])+'/'\n",
    "    mk(FOLDER_TRAIN+''+dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angle': -158.4429207149623,\n",
       " 'class': 'ALB',\n",
       " 'code': 2,\n",
       " 'filename': 'img_00003.jpg',\n",
       " 'head_tail': [{'x': 825.5028464692997, 'y': 342.8499725255559},\n",
       "  {'x': 1095.1227277758048, 'y': 449.36646884417524}],\n",
       " 'height': 720,\n",
       " 'ht_first': True,\n",
       " 'path': './train/ALB/img_00003.jpg',\n",
       " 'rectangles': [{'height': 170.61000000000257,\n",
       "   'width': 332.7600000000051,\n",
       "   'x': 805.1100000000123,\n",
       "   'y': 324.30000000000496},\n",
       "  {'height': 258.03000000000395,\n",
       "   'width': 377.88000000000574,\n",
       "   'x': 266.49000000000404,\n",
       "   'y': 135.36000000000206},\n",
       "  {'height': 100.11000000000152,\n",
       "   'width': 360.96000000000555,\n",
       "   'x': 375.0600000000057,\n",
       "   'y': 56.40000000000086},\n",
       "  {'height': 105.75000000000162,\n",
       "   'width': 335.58000000000516,\n",
       "   'x': 690.9000000000106,\n",
       "   'y': 88.83000000000135}],\n",
       " 'width': 1280}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"img_00003.jpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, let's create the network that will be shared:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is the final network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = [np.zeros((5,5,1,1))]\n",
    "for i in range(5):\n",
    "    n[0][i,i,0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "\n",
    "    x = MaxPooling2D((kernel_size, kernel_size), strides=(1,1),\n",
    "                      border_mode='same', name=conv_name_base + '2b')(input_tensor)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    layer1 = Convolution2D(5, 1, 1, subsample=strides, bias=False, weights=n,\n",
    "                      name=conv_name_base + '2a')\n",
    "    x = layer1(input_tensor)\n",
    "    \n",
    "    layer2 = MaxPooling2D((kernel_size, kernel_size), strides=(1,1), border_mode='same',\n",
    "                      name=conv_name_base + '2b')\n",
    "    x = layer2(x)\n",
    "    \n",
    "\n",
    "    layer3 = Convolution2D(5, 1, 1, subsample=strides, bias=False, weights=n,\n",
    "                             name=conv_name_base + '1')\n",
    "    \n",
    "    shortcut = layer3(input_tensor)\n",
    "    print(layer1.output_shape)\n",
    "    print(layer2.output_shape)\n",
    "    print(layer3.output_shape)\n",
    "    x = merge([x, shortcut], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet501(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None):\n",
    "    '''Instantiate the ResNet50 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        inputs_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "            or `(3, 224, 244)` (with `th` dim ordering).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    img_input = Input(shape=(5,1344,2240))\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = MaxPooling2D((7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = MaxPooling2D((7, 7),strides=(1,1), name='avg_pool')(x)\n",
    "\n",
    "    x = Reshape((5, 36*64))(x)\n",
    "    x = Permute((2, 1))(x)\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 335, 559)\n",
      "(None, 5, 335, 559)\n",
      "(None, 5, 335, 559)\n",
      "(None, 5, 168, 280)\n",
      "(None, 5, 168, 280)\n",
      "(None, 5, 168, 280)\n",
      "(None, 5, 84, 140)\n",
      "(None, 5, 84, 140)\n",
      "(None, 5, 84, 140)\n",
      "(None, 5, 42, 70)\n",
      "(None, 5, 42, 70)\n",
      "(None, 5, 42, 70)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet501()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((2, 5, 1344, 2240))\n",
    "a[0,0,500,500] =1\n",
    "a[0,1,500,1000] =1\n",
    "a[0,2,700,500] =1\n",
    "a[0,3,700,1000] =1\n",
    "a[0,4,600,750] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmp9as3yh7r/m9a6bd0eb5ed5c92e91261282fc495cb4.lib and object C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmp9as3yh7r/m9a6bd0eb5ed5c92e91261282fc495cb4.exp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = resnet.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADfCAYAAADmzyjKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY0w0CWpEQa6JDXCQJekRhjoktSI/wNLhkk+ST8iVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1497a5ba550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = np.swapaxes(b,1,2).reshape((2,5,36,64))\n",
    "plt.imshow(c[0,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADfCAYAAADmzyjKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY0w0CWpEQa6JDXCQJekRhjoktSI/wNLhkk+ST8iVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1497acf1240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = np.swapaxes(c.reshape((2, 5, 36*64)),2,1)\n",
    "e = np.swapaxes(d,1,2).reshape((2,5,36,64))\n",
    "plt.imshow(e[0,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_model(pool_branches = [(2,2), (4,4), (5,5), (8,8),(10,10)]):\n",
    "    nb_input_filters = 1000\n",
    "    N = 36\n",
    "    \n",
    "    img_input = Input(shape=(5,None,None))\n",
    "\n",
    "    W = []\n",
    "    for i in range(N):\n",
    "        if i == 0:\n",
    "            w = img_input\n",
    "            W.append(w)\n",
    "        else:\n",
    "            #if (i+2,i+2) in pool_branches:\n",
    "            w = MaxPooling2D(pool_size=(i+1,i+1), strides=(1,1))(img_input)\n",
    "            W.append(w)\n",
    "\n",
    "    model = Model(input=img_input, output=W)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n",
      "(None, 5, None, None)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet501()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = Input(shape=(5,1344,2240))\n",
    "d = resnet(b)\n",
    "x = model1(d)\n",
    "final_model = Model(input=b,output=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's insert the imageNet weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function gives the 4 corners of the rectangle in a mask with a size\n",
    "# different from the image size\n",
    "def get_4_points(rectangle, height,width, target_height, target_width):\n",
    "    ratio_y = height/target_height\n",
    "    ratio_x = width/target_width\n",
    "    new_x = rectangle[\"x\"]/ratio_x\n",
    "    new_y = rectangle[\"y\"]/ratio_y\n",
    "    new_x2 = (rectangle[\"x\"]+rectangle[\"width\"])/ratio_x\n",
    "    new_y2 = (rectangle[\"y\"]+rectangle[\"height\"])/ratio_y\n",
    "    result = np.zeros((5,2))\n",
    "    result[:2,0] = new_x\n",
    "    result[2:,0] = new_x2\n",
    "    result[0,1] = new_y\n",
    "    result[2,1] = new_y\n",
    "    result[1,1] = new_y2\n",
    "    result[3,1] = new_y2\n",
    "    result[:,0].clip(min=0, max=target_width-1, out=result[:,0])\n",
    "    result[:,1].clip(min=0, max=target_height-1, out=result[:,1])\n",
    "    result[4] = (result[0] + result[3])/2\n",
    "    result = result.astype(int)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# This is to remove the useless first dimention because our batch\n",
    "# size is one.\n",
    "def remove_dims(list_matrices):\n",
    "    return [x[0] for x in list_matrices]\n",
    "\n",
    "\n",
    "# This function takes a matrix and multiply all the sub-matrix\n",
    "# element-wise along the axis 0.\n",
    "def elementwise_multiplication(matrix):\n",
    "    \n",
    "    result = np.ones(matrix.shape[1:])\n",
    "    for i in range(matrix.shape[0]):\n",
    "        np.multiply(result, matrix[i], out = result)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def fuse_squares(matrix):\n",
    "    \n",
    "    result = np.ones(matrix.shape[1:])*0.5\n",
    "    \n",
    "    no_fish = np.where(np.sum(matrix,axis=0)==0)\n",
    "    fish = np.where(elementwise_multiplication(matrix)==1)\n",
    "    \n",
    "    result[no_fish]=1\n",
    "    result[fish]=0\n",
    "\n",
    "    return result\n",
    "\n",
    "def fuse_fishes(matrix):\n",
    "    result = np.ones(matrix.shape[1:])*0.5\n",
    "    \n",
    "    no_fish = np.where(elementwise_multiplication(matrix)==1)\n",
    "    fish = np.where(elementwise_multiplication(matrix)==0)\n",
    "    \n",
    "    result[no_fish]=1\n",
    "    result[fish]=0\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_zones(res):\n",
    "    return [ fuse_squares(matrix) for matrix in res]\n",
    "\n",
    "def get_zones_with_rects(list_masks):\n",
    "    \n",
    "    # Reshaping phase:\n",
    "    list_reshaped = []\n",
    "    for j in range(len(list_masks[0])):\n",
    "        matrix = np.zeros((len(list_masks),) + list_masks[0][j].shape)\n",
    "        for i in range(len(list_masks)):\n",
    "            matrix[i] = list_masks[i][j]\n",
    "        list_reshaped.append(matrix)\n",
    "        \n",
    "    # Now we do the intersection and stuff\n",
    "    return [fuse_fishes(matrix) for matrix in list_reshaped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpzh2uni8c/m9a6bd0eb5ed5c92e91261282fc495cb4.lib and object C:/Users/yolo/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpzh2uni8c/m9a6bd0eb5ed5c92e91261282fc495cb4.exp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder1 = \"folder_store_masks/npy/\"\n",
    "folder2 = \"folder_store_masks/png/\"\n",
    "utils.mk(folder1)\n",
    "utils.mk(folder2)\n",
    "for key, v in tq(list(metadata.items())):\n",
    "    if v[\"class\"] != \"NoF\":\n",
    "        if \"rectangles\" in v:\n",
    "            \n",
    "            utils.mk(folder1 + v[\"filename\"])\n",
    "            utils.mk(folder2 + v[\"filename\"])\n",
    "            \n",
    "            list_masks = []\n",
    "            \n",
    "            for rec in v[\"rectangles\"]:\n",
    "                points = get_4_points(rec, v[\"height\"], v[\"width\"], 1344, 2240)\n",
    "                matrice = np.zeros((1, points.shape[0] ,1344,2240))\n",
    "                \n",
    "                for k in range(points.shape[0]):\n",
    "                    matrice[0,k,points[k,1],points[k,0]] = 1\n",
    "\n",
    "                out_branches = final_model.predict(matrice)\n",
    "                out_branches = remove_dims(out_branches)\n",
    "                list_masks.append(get_zones(out_branches))\n",
    "                \n",
    "            if len(list_masks)>1:\n",
    "                list_masks = get_zones_with_rects(list_masks)\n",
    "            elif len(list_masks) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                list_masks = list_masks[0]\n",
    "                \n",
    "            # We create the one hot encoding and save the result.\n",
    "            for mask in list_masks:\n",
    "                \n",
    "                one_hot = np.zeros((8,) + mask.shape)\n",
    "                \n",
    "                # We fill the one hot encoding vector. No value means that we don't know the result.\n",
    "                one_hot[0][np.where(mask==1)]=1\n",
    "                one_hot[v[\"code\"]][np.where(mask==0)]=1\n",
    "                \n",
    "                # We save also the mask for debug purposes.\n",
    "                array_to_img(np.expand_dims(mask,0)).save(folder2 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]) + \".png\")\n",
    "                \n",
    "                one_hot = one_hot.astype(bool)\n",
    "                utils.save_array(one_hot, folder1 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]))\n",
    "        \n",
    "                    \n",
    "    # No fish case\n",
    "    else:\n",
    "        \n",
    "        # We create the one hot encoding heatmap and save the result.\n",
    "        for i in range(1,37):\n",
    "            utils.mk(folder1 + v[\"filename\"])\n",
    "            utils.mk(folder2 + v[\"filename\"])\n",
    "            \n",
    "            one_hot = np.zeros((8,i,i+28))\n",
    "            one_hot[0,:,:]=1\n",
    "            \n",
    "            array_to_img(np.expand_dims(one_hot[0],0)).save(folder2 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]) + \".png\")\n",
    "            \n",
    "            one_hot = one_hot.astype(bool)\n",
    "            utils.save_array(one_hot, folder1 + v[\"filename\"] + \"/\" + str(one_hot.shape[1:]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need the last weights of the resnet50:\n",
    "resnet = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heatmap.insert_weights(resnet.layers[-1], model.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = \"models/resnet_mask_training.h5\"\n",
    "mk('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can now save the model.\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth step, training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del resnet\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = \"models/resnet_mask_training.h5\"\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=adam, sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, training_set, metadata,image_size)\n",
    "test_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size)\n",
    "history = model.fit_generator(train_gen, samples_per_epoch=2, nb_epoch=150, callbacks=[remote], \n",
    "                              verbose=0,validation_data=test_gen, nb_val_samples=2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers[2].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.0, nesterov=True)\n",
    "adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mse', optimizer=sgd, sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, training_set, metadata,image_size)\n",
    "test_gen = DiskArrayIterator(2, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size)\n",
    "history = model.fit_generator(train_gen, samples_per_epoch=2, nb_epoch=25, callbacks=[remote], \n",
    "                              verbose=0,validation_data=test_gen, nb_val_samples=2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_trained = \"models/fish_detection_trained_1.1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(file_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(file_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth step, display results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> STATISCAL ANALYSIS OF MEAN_MAX RESULTS </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Final = []\n",
    "c = tq(total=100*16)\n",
    "N = 100\n",
    "n = 0\n",
    "for X, Y, W , paths,is_rects in DiskArrayIterator(16, nb_filters, mask_size, FOLDER_TRAIN, test_set, metadata,image_size, with_name=True, shuffle=False,debug2=True):\n",
    "    Z = model.predict(X)   \n",
    "    n +=1\n",
    "    if n < N:\n",
    "        for i in range(16):\n",
    "            c.update()\n",
    "            maxs = []\n",
    "            for j in range(5):\n",
    "                maxs.append(np.max(Z[j][i]))\n",
    "            mean_max = np.array(maxs).mean()\n",
    "            try:\n",
    "                Final.append([mean_max,is_rects[i]])\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        break\n",
    "import pickle        \n",
    "pickle.dump( Final, open( \"Final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final = pickle.load( open( \"Final.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF TEST : 1560\n",
      "mean w_f : 0.648588\n",
      "mean wo_f : 0.246224\n",
      "min w_f : 0.0959474\n",
      "min wo_f : 0.059991\n",
      "std w_f : 0.271008\n",
      "std wo_f : 0.129603\n",
      "THRESHOLD : 0.377581\n"
     ]
    }
   ],
   "source": [
    "w_f = []\n",
    "wo_f = []\n",
    "for i in range(len(Final)):\n",
    "    if Final[i][1]:\n",
    "        w_f.append(Final[i][0])\n",
    "    else:\n",
    "        wo_f.append(Final[i][0])\n",
    "w_f = np.array(w_f) \n",
    "wo_f = np.array(wo_f) \n",
    "print('LENGTH OF TEST : '+str(len(Final)))\n",
    "print('mean w_f : '+str(np.array(w_f).mean()))\n",
    "print('mean wo_f : '+str(np.array(wo_f).mean()))\n",
    "print('min w_f : '+str(np.array(w_f).min()))\n",
    "print('min wo_f : '+str(np.array(wo_f).min()))\n",
    "print('std w_f : '+str(np.array(w_f).std()))\n",
    "print('std wo_f : '+str(np.array(wo_f).std()))\n",
    "print('THRESHOLD : '+str(np.array(w_f).mean() - np.array(w_f).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'heatmaps_to_rect' from '../python_scripts\\\\heatmaps_to_rect.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(htr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(paths[i])\n",
    "    plt.imshow(load_img(paths[i]))\n",
    "    plt.show()\n",
    "    maxs = []\n",
    "    for j in range(5):\n",
    "        plt.figure(figsize=(24,24))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(np.reshape(Y[j][i],mask_size[1]))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(np.reshape(Z[j][i],mask_size[1]))\n",
    "        plt.show()\n",
    "        print(\"max: \", np.max(Z[j][i]))\n",
    "        print(\"min: \", np.min(Z[j][i]))\n",
    "        maxs.append(np.max(Z[j][i]))\n",
    "    mean_max = np.array(maxs).mean()\n",
    "    masks = np.array([np.reshape(Z[j][i],mask_size[1]) for j in range(5)])\n",
    "    print(masks.shape)\n",
    "    #rectangles = htr.find_rectangles([masks],mean_max, threshold=100, ranges=(5,20), clip=0.20, debug=True,\n",
    "    #                    border_conf=[(11,3),(71,10)], batch_size=1, max_fish=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
