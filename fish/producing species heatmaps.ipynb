{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, '../python_scripts')\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import utils\n",
    "import importlib\n",
    "import threading\n",
    "import meta\n",
    "import heatmap\n",
    "metadata = utils.load(\"./variables/metadata.p\")\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras import callbacks\n",
    "from keras.preprocessing.image import Iterator\n",
    "import os\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import heatmap\n",
    "remote = callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "from shutil import copyfile\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import time\n",
    "import h_gen,meta,heatmap\n",
    "from meta import *\n",
    "from h_gen import *\n",
    "from utils import *\n",
    "import gc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = [(768, 1216),(1344,2240)]\n",
    "FOLDER_TRAIN = \"./temp_training/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../JSONS/alb_labels.json', '../JSONS/bet_labels.json', '../JSONS/dol_labels.json', '../JSONS/lag_labels.json', '../JSONS/other_labels.json', '../JSONS/shark_labels.json', '../JSONS/yft_labels.json']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SPLIT = 0.8 # For the train/test split\n",
    "metadata = meta.create_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img_size in image_size:\n",
    "    dim = str(img_size[0])+'_'+str(img_size[1])+'/'\n",
    "    mk(FOLDER_TRAIN+''+dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, let's create the network that will be shared:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is the final network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [np.zeros((4,4,1,1))]\n",
    "for i in range(4):\n",
    "    a[0][i,i,0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "\n",
    "    x = MaxPooling2D((kernel_size, kernel_size), strides=(1,1),\n",
    "                      border_mode='same', name=conv_name_base + '2b')(input_tensor)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    layer1 = Convolution2D(4, 1, 1, subsample=strides, bias=False, weights=a,\n",
    "                      name=conv_name_base + '2a')\n",
    "    x = layer1(input_tensor)\n",
    "    \n",
    "    layer2 = MaxPooling2D((kernel_size, kernel_size), strides=(1,1), border_mode='same',\n",
    "                      name=conv_name_base + '2b')\n",
    "    x = layer2(x)\n",
    "    \n",
    "\n",
    "    layer3 = Convolution2D(4, 1, 1, subsample=strides, bias=False, weights=a,\n",
    "                             name=conv_name_base + '1')\n",
    "    \n",
    "    shortcut = layer3(input_tensor)\n",
    "    x = merge([x, shortcut], mode='max')\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet501(include_top=True, weights='imagenet',\n",
    "             input_tensor=None, input_shape=None):\n",
    "    '''Instantiate the ResNet50 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        inputs_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "            or `(3, 224, 244)` (with `th` dim ordering).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 197.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    img_input = Input(shape=(4,None,None))\n",
    "\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    x = MaxPooling2D((7, 7), strides=(2, 2), name='conv1')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = MaxPooling2D((7, 7),strides=(1,1), name='avg_pool')(x)\n",
    "\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n",
      "(None, 4, None, None)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNet501()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_matrix = np.zeros((1,4,768,1216))\n",
    "my_ = np.zeros((1,4,1344,2240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_matrix[0,0,0,0] = 1\n",
    "my_matrix[0,1,100,0] = 1\n",
    "my_matrix[0,2,0,300] = 1\n",
    "my_matrix[0,3,100,300] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = final_model.predict([my_matrix,my_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 6, 34)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res[30][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABdCAYAAACFO4w4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABjBJREFUeJzt3U2IXXcZx/Hvz2nSSFRstZaSRG2hm1KkQoibIBVRUjdR\nF6VZ1VVcaKk7ixurIIiouBEhYqCCWgq1mkVRohTUTc20RPuuoUSaISZKERvBpC+Pi3sGp+O83NY5\nmXku3w+EuffM4Z7n4eH+5t7/PfckVYUkqY+3bHYBkqQ3xuCWpGYMbklqxuCWpGYMbklqxuCWpGYM\nbklqxuCWpGYMbklq5ooxHnR7rqwd7BzjoSVpJv2bf3GpLmaafUcJ7h3s5EP56BgPLUkz6dH69dT7\nTrVUkuRAkueSnEpyz5uuTJL0f1s3uJPMAd8FbgNuAg4luWnswiRJK5vmFfc+4FRVPV9Vl4D7gYPj\nliVJWs00wb0LeGHJ/TPDttdJcjjJfJL5l7m4UfVJkpbZsNMBq+pIVe2tqr3buHKjHlaStMw0wb0A\n7Flyf/ewTZK0CaYJ7hPAjUmuT7IduAM4Nm5ZkqTVrHsed1W9kuTzwC+BOeBoVT01emWSpBVN9QWc\nqnoYeHjkWiRJU/BaJZLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y\n3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLU\njMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEtSc0Y3JLUjMEt\nSc0Y3JLUjMEtSc0Y3JLUjMEtSc1cMc1OSU4DLwGvAq9U1d4xi5IkrW6q4B58pKr+PlolkqSpuFQi\nSc1MG9wF/CrJY0kOr7RDksNJ5pPMv8zFjatQkvQ60y6V7K+qhSTvAY4nebaqfrN0h6o6AhwBeEeu\nrg2uU5I0mOoVd1UtDD/PAw8B+8YsSpK0unWDO8nOJG9fvA18HHhy7MIkSSubZqnkWuChJIv7/7iq\nfjFqVZKkVaVq45ejk/wN+MuSTe8GZuFUwlnowx62hlnoAWajj63Sw/uq6pppdhwluP/nIMn8LHxp\nZxb6sIetYRZ6gNnoo2MPnsctSc0Y3JLUzOUK7iOX6Thjm4U+7GFrmIUeYDb6aNfDZVnjliRtHJdK\nJKkZg1uSmhk9uJMcSPJcklNJ7hn7eGNIcjrJE0lOJpnf7HqmleRokvNJnlyy7eokx5P8efh51WbW\nuJ5Verg3ycIwj5NJPrGZNa4nyZ4kjyR5OslTSe4etreZxRo9tJlFkh1Jfp/kD0MPXxm2t5nDolHX\nuJPMAX8CPgacAU4Ah6rq6dEOOoLhP5LY2+165Ek+DFwAflhVNw/bvgG8WFVfH/6QXlVVX9zMOtey\nSg/3Aheq6pubWdu0klwHXFdVjw+Xj3gM+CTwGZrMYo0ebqfJLDL5+vfOqrqQZBvwO+Bu4NM0mcOi\nsV9x7wNOVdXzVXUJuB84OPIxNRiu4Pjiss0HgfuG2/cxefJtWav00EpVna2qx4fbLwHPALtoNIs1\nemijJi4Md7cN/4pGc1g0dnDvAl5Ycv8MzYY9WPd65I1cW1Vnh9t/ZXItmo7uSvLHYSlly7+1XZTk\n/cAHgUdpOotlPUCjWSSZS3ISOA8cr6qWc/DDyensr6pbgNuAzw1v39uryTpZx/NBvwfcANwCnAW+\ntbnlTCfJ24AHgS9U1T+X/q7LLFboodUsqurV4bm8G9iX5OZlv28xh7GDewHYs+T+7mFbKzN2PfJz\nw3rl4rrl+U2u5w2rqnPDE/A14Ps0mMewpvog8KOq+umwudUsVuqh4ywAquofwCPAAZrNAcYP7hPA\njUmuT7IduAM4NvIxN9QMXo/8GHDncPtO4OebWMubsvgkG3yKLT6P4UOxHwDPVNW3l/yqzSxW66HT\nLJJck+Sdw+23Mjlp4lkazWHR6N+cHE4P+g4wBxytqq+NesANluQGJq+y4b/XI2/RQ5KfALcyuWzl\nOeDLwM+AB4D3Mrn07u1VtWU//Fulh1uZvDUv4DTw2SVrlFtOkv3Ab4EngNeGzV9iskbcYhZr9HCI\nJrNI8gEmHz7OMXnR+kBVfTXJu2gyh0V+5V2SmvHDSUlqxuCWpGYMbklqxuCWpGYMbklqxuCWpGYM\nbklq5j8GMCgvT+kppQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1546d0f21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(res[30][0][3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_model(pool_branches = [(2,2), (4,4), (5,5), (8,8),(10,10)]):\n",
    "    nb_input_filters = 1000\n",
    "    N = 36\n",
    "    \n",
    "    img_inputs = [Input(shape=(4,None,None)) for _ in range(2)]\n",
    "\n",
    "    x,y = tuple(img_inputs)\n",
    "\n",
    "\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    merge_out = Merge(mode='max')([x,y])\n",
    "\n",
    "    W = []\n",
    "    for i in range(N):\n",
    "        if i == 0:\n",
    "            w = merge_out\n",
    "            W.append(w)\n",
    "        else:\n",
    "            #if (i+2,i+2) in pool_branches:\n",
    "            w = MaxPooling2D(pool_size=(i+1,i+1), strides=(1,1))(merge_out)\n",
    "            W.append(w)\n",
    "\n",
    "    model = Model(input=img_inputs, output=W)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Input(shape=(4,768,1216))\n",
    "b = Input(shape=(4,1344,2240))\n",
    "c= resnet(a)\n",
    "d = resnet(b)\n",
    "x = model1([c,d])\n",
    "final_model = Model(input=[a,b],output=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function gives the 4 corners of the rectangle in a mask with a size\n",
    "# different from the image size\n",
    "def get_4_points(rectangle, height,width, target_height, target_width):\n",
    "    ratio_y = height/target_height\n",
    "    ratio_x = width/target_width\n",
    "    new_x = rectangle[\"x\"]/ratio_x\n",
    "    new_y = rectangle[\"y\"]/ratio_y\n",
    "    new_x2 = rectangle[\"x\"]+rectangle[\"width\"]/ratio_x\n",
    "    new_y2 = rectangle[\"y\"]+rectangle[\"height\"]/ratio_y\n",
    "    result = np.zeros((4,2))\n",
    "    result[:2,0] = new_x\n",
    "    result[2:,0] = new_x2\n",
    "    result[0,1] = new_y\n",
    "    result[2,1] = new_y\n",
    "    result[1,1] = new_y2\n",
    "    result[3,1] = new_y2\n",
    "    result[:,0].clip(min=0, max=target_width, out=result[:,0])\n",
    "    result[:,1].clip(min=0, max=target_height, out=result[:,1])\n",
    "    result = result.astype(int)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angle': -158.4429207149623,\n",
       " 'class': 'ALB',\n",
       " 'code': 2,\n",
       " 'filename': 'img_00003.jpg',\n",
       " 'head_tail': [{'x': 825.5028464692997, 'y': 342.8499725255559},\n",
       "  {'x': 1095.1227277758048, 'y': 449.36646884417524}],\n",
       " 'height': 720,\n",
       " 'ht_first': True,\n",
       " 'path': './train/ALB/img_00003.jpg',\n",
       " 'rectangles': [{'height': 170.61000000000257,\n",
       "   'width': 332.7600000000051,\n",
       "   'x': 805.1100000000123,\n",
       "   'y': 324.30000000000496},\n",
       "  {'height': 258.03000000000395,\n",
       "   'width': 377.88000000000574,\n",
       "   'x': 266.49000000000404,\n",
       "   'y': 135.36000000000206},\n",
       "  {'height': 100.11000000000152,\n",
       "   'width': 360.96000000000555,\n",
       "   'x': 375.0600000000057,\n",
       "   'y': 56.40000000000086},\n",
       "  {'height': 105.75000000000162,\n",
       "   'width': 335.58000000000516,\n",
       "   'x': 690.9000000000106,\n",
       "   'y': 88.83000000000135}],\n",
       " 'width': 1280}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"img_00003.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_01784.jpg\n",
      "img_03576.jpg\n",
      "img_02452.jpg\n",
      "img_06588.jpg\n",
      "img_06587.jpg\n",
      "img_06884.jpg\n",
      "img_00020.jpg\n",
      "img_05135.jpg\n",
      "img_04583.jpg\n",
      "img_06421.jpg\n",
      "img_01917.jpg\n",
      "img_06536.jpg\n",
      "img_06693.jpg\n",
      "img_06670.jpg\n",
      "img_06198.jpg\n",
      "img_07465.jpg\n",
      "img_04301.jpg\n",
      "img_04090.jpg\n",
      "img_07549.jpg\n",
      "img_06656.jpg\n",
      "img_06656.jpg\n",
      "img_03620.jpg\n",
      "img_07891.jpg\n",
      "img_06340.jpg\n",
      "img_02671.jpg\n",
      "img_01869.jpg\n",
      "img_00091.jpg\n",
      "img_05804.jpg\n",
      "img_07657.jpg\n",
      "img_07299.jpg\n",
      "img_02491.jpg\n",
      "img_02342.jpg\n",
      "img_01838.jpg\n",
      "img_07212.jpg\n",
      "img_05225.jpg\n",
      "img_07545.jpg\n",
      "img_06887.jpg\n",
      "img_06461.jpg\n",
      "img_06224.jpg\n",
      "img_06873.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for key, v in list(metadata.items())[:2]:\n",
    "        if v[\"class\"] != \"NoF\":\n",
    "            if \"rectangles\" in v:\n",
    "                for rec in v[\"rectangles\"]:\n",
    "                    points = get_4_points(rec, v[\"height\"], v[\"width\"], size[i][0], size[i][1])\n",
    "                    matrice = np.zeros((1,4,1344,2240))\n",
    "                    for k in range(4):\n",
    "                        matrices[0,k,points[k,0],points[k,1]] = 1\n",
    "                    out_branches = final_model.predict(matrice)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
